{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29d90467",
   "metadata": {},
   "source": [
    "# Test-time Training Exploration: Hindsight Experience Replay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944074db",
   "metadata": {},
   "source": [
    "## Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2f49b5",
   "metadata": {},
   "source": [
    "Can I solve tasks using test-time training?\n",
    "\n",
    "I want to explore different TTT techniques such as hindsight experience replay and RL to see if a model can solve novel tasks that cannot be solve with the base model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1580a327",
   "metadata": {},
   "source": [
    "I have to focus on the techniques, not on efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32b9cf8",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1824b435",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from vllm import LLM, SamplingParams\n",
    "from vllm.lora.request import LoRARequest\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from datasets import Dataset\n",
    "from trl import SFTTrainer, DataCollatorForCompletionOnlyLM, SFTConfig\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import PeftModel\n",
    "import logging\n",
    "from IPython.display import Markdown, display\n",
    "import torch\n",
    "\n",
    "\n",
    "from arc25.training_tasks import *\n",
    "from arc25.encoders import create_grid_encoder\n",
    "from arc25.prompting import create_prompt_from_task, pretty_print_prompt\n",
    "from arc25.plot import plot_task, plot_grids_with_shape, plot_grid\n",
    "from arc25.code_execution import safe_code_execution\n",
    "from arc25.utils import set_random_seed\n",
    "from arc25.logging import configure_logging, log_execution_time\n",
    "\n",
    "configure_logging()\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.path.realpath(\"../scripts\"))\n",
    "from finetuning import get_data_collator\n",
    "\n",
    "\n",
    "plt.plot()\n",
    "plt.close('all')\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 5)\n",
    "mpl.rcParams['lines.linewidth'] = 3\n",
    "mpl.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0f6f77",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bd1f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "EpochResults = namedtuple(\"EpochResults\", [\"best_prediction\", 'pixel_accuracies'])\n",
    "\n",
    "@log_execution_time\n",
    "def hindsight_experience_replay(task, cfg):\n",
    "    \"\"\"\n",
    "    Use hindsight experience replay to try to solve new tasks\n",
    "    \"\"\"\n",
    "    plot_task(task); plt.suptitle('Task to solve'); plt.tight_layout(); plt.show()\n",
    "    model, tokenizer = load_model(cfg.base_model_path, cfg.lora_path)\n",
    "    metrics = []\n",
    "    for epoch in range(cfg.max_epochs):\n",
    "        logging.info(f'Starting epoch {epoch}...')\n",
    "        new_tasks, pixel_accuracies = inference(\n",
    "            task, model, tokenizer, cfg.grid_encoder, cfg.prompt_version,\n",
    "            n_predictions=cfg.n_predictions)\n",
    "        plot_best_prediction(task, new_tasks[-1], max(pixel_accuracies))\n",
    "        metrics.append(EpochResults(best_prediction=new_tasks[-1], pixel_accuracies=pixel_accuracies))\n",
    "        if np.max(pixel_accuracies) == 1:\n",
    "            logger.info(f'Found a perfect prediction at epoch {epoch}!')\n",
    "            break\n",
    "        finetuning(new_tasks, model, tokenizer, cfg.grid_encoder, cfg.prompt_version)\n",
    "    plot_metrics_evolution(metrics)\n",
    "    return metrics\n",
    "\n",
    "@log_execution_time\n",
    "def load_model(base_model_path, lora_path):\n",
    "    logging.info(f\"Loading model from {base_model_path} and LoRA from {lora_path}\")\n",
    "    torch.cuda.empty_cache()\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        base_model_path, torch_dtype=\"auto\", device_map=\"auto\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(lora_path)\n",
    "    model = PeftModel.from_pretrained(model, lora_path, is_trainable=True)\n",
    "    return model, tokenizer\n",
    "\n",
    "@log_execution_time\n",
    "def inference(task, model, tokenizer, grid_encoder, prompt_version, n_predictions=256):\n",
    "    prompt = create_prompt_from_task(\n",
    "        task, prompt_version=prompt_version, grid_encoder=grid_encoder, tokenizer=tokenizer, is_train_prompt=False)\n",
    "    model_inputs = tokenizer([prompt], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    generated_ids = model.generate(\n",
    "        **model_inputs,\n",
    "        max_new_tokens=1024,\n",
    "        do_sample=True,\n",
    "        temperature=0.5,\n",
    "        top_p=0.95,\n",
    "        num_return_sequences=n_predictions\n",
    "    )\n",
    "    generated_ids = generated_ids[:, len(model_inputs.input_ids[0]):]\n",
    "    predictions = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "\n",
    "    predicted_codes = [prediction.replace('\\n```', '') for prediction in predictions]\n",
    "    new_tasks = []\n",
    "    pixel_accuracies = []\n",
    "    for predicted_code in tqdm(predicted_codes):\n",
    "        try:\n",
    "            predicted_output = safe_code_execution(predicted_code, task.inputs)\n",
    "            new_tasks.append(Task(inputs=task.inputs, outputs=predicted_output, code=predicted_code, name=task.name))\n",
    "            pixel_accuracies.append(float(np.mean(new_tasks[-1].outputs[0] == task.outputs[0])))\n",
    "        except Exception as e:\n",
    "                print(f'Error executing code: {predicted_code}')\n",
    "                print(e)\n",
    "    plt.hist(pixel_accuracies, bins=np.linspace(0, 1, 100), log=True, label='all predictions');\n",
    "\n",
    "    new_tasks_with_unique_outputs = [new_tasks[0]]\n",
    "    filtered_pixel_accuracies = []\n",
    "    for new_task in new_tasks[1:]:\n",
    "        if not any([np.all(new_task.outputs[0] == t.outputs[0]) for t in new_tasks_with_unique_outputs]):\n",
    "            new_tasks_with_unique_outputs.append(new_task)\n",
    "            filtered_pixel_accuracies.append(float(np.mean(new_task.outputs[0] == task.outputs[0])))\n",
    "    logging.info(f'Number of unique outputs: {len(new_tasks_with_unique_outputs)}/{len(new_tasks)}')\n",
    "    logging.info(f'Max pixel accuracy: {max(pixel_accuracies)}')\n",
    "\n",
    "    plt.hist(filtered_pixel_accuracies, bins=np.linspace(0, 1, 100), log=True, label='unique predictions', alpha=0.5);\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    new_tasks_with_unique_outputs = sorted(new_tasks_with_unique_outputs, key=lambda x: float(np.mean(x.outputs[0] == task.outputs[0])), reverse=False)\n",
    "    return new_tasks_with_unique_outputs, pixel_accuracies\n",
    "\n",
    "@log_execution_time\n",
    "def finetuning(new_tasks, model, tokenizer, grid_encoder, prompt_version):\n",
    "    prompts = []\n",
    "    for task in new_tasks:\n",
    "        prompts.append(create_prompt_from_task(\n",
    "    task, prompt_version=prompt_version, grid_encoder=grid_encoder, tokenizer=tokenizer, is_train_prompt=True))\n",
    "    train_dataset = Dataset.from_dict({'text': prompts})\n",
    "\n",
    "    training_arguments = SFTConfig(\n",
    "        output_dir='/mnt/hdd0/Kaggle/arc25/trainings/20250505_TTT/debug',\n",
    "        num_train_epochs=1,\n",
    "        warmup_ratio=0.1,\n",
    "        learning_rate=1e-5,\n",
    "        lr_scheduler_type='constant_with_warmup', #constant_with_warmup, cosine, cosine_with_restarts\n",
    "        # lr_scheduler_kwargs=lr_scheduler_kwargs,\n",
    "        gradient_checkpointing=False,\n",
    "        optim=\"paged_adamw_8bit\",\n",
    "        max_grad_norm=1.0,\n",
    "\n",
    "        dataset_text_field=\"text\",\n",
    "        max_seq_length=4096,\n",
    "\n",
    "        do_eval=True,\n",
    "        eval_strategy=\"no\", #TODO: previously it was steps\n",
    "        # save_steps=cfg.save_steps or cfg.eval_steps,\n",
    "        logging_steps=10, #50,\n",
    "        log_level=\"info\",\n",
    "        report_to='none',\n",
    "\n",
    "        # parameters added to make the code work with accelerate\n",
    "        # dispatch_batches=False,\n",
    "        # https://huggingface.co/transformers/v4.9.1/main_classes/trainer.html#trainingarguments\n",
    "        ddp_find_unused_parameters=False, # only used with accelerate, got a warning saying that it slows down if True\n",
    "\n",
    "        ignore_data_skip=True, # otherwise it takes too long to start training when resuming from checkpoint\n",
    "\n",
    "        per_device_train_batch_size=1,\n",
    "        gradient_accumulation_steps=1,\n",
    "    )\n",
    "\n",
    "    trainer = SFTTrainer(\n",
    "        model=model,\n",
    "        processing_class=tokenizer,\n",
    "        train_dataset=train_dataset,\n",
    "        data_collator=get_data_collator(tokenizer),\n",
    "        args=training_arguments,\n",
    "    )\n",
    "    trainer.train()\n",
    "\n",
    "\n",
    "def plot_best_prediction(task, best_prediction, accuracy):\n",
    "    plot_grids_with_shape(task.outputs + best_prediction.outputs, suptitle=f'Best prediction accuracy: {accuracy:.1%}')\n",
    "    display(Markdown(f'```python\\n{best_prediction.code}\\n```'))\n",
    "\n",
    "\n",
    "def plot_metrics_evolution(metrics):\n",
    "    plot_score_histograms(metrics)\n",
    "\n",
    "    for epoch, epoch_results in enumerate(metrics):\n",
    "        plt.subplot(1, len(metrics), epoch + 1)\n",
    "        plot_grid(epoch_results.best_prediction.outputs[0])\n",
    "        plt.title(f'Epoch {epoch} acc: {max(epoch_results.pixel_accuracies):.1%}')\n",
    "    plt.suptitle('Evolution of best predictions')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_score_histograms(metrics, offset_scale=1):\n",
    "    \"\"\"\n",
    "    Plots stacked (y-offset) histograms\n",
    "    \"\"\"\n",
    "    cmap = mpl.colormaps['viridis']#get_cmap(\"viridis\")\n",
    "    norm = plt.Normalize(0, len(metrics) - 1)\n",
    "    bins = np.linspace(0, 1, 100)\n",
    "    bin_centers = 0.5 * (bins[1:] + bins[:-1])\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i, epoch_results in enumerate(metrics):\n",
    "        color = cmap(norm(i))\n",
    "        counts, _ = np.histogram(epoch_results.pixel_accuracies, bins=bins)\n",
    "        counts = np.log1p(counts)\n",
    "        offset = i * np.max(counts) * offset_scale  # Add spacing between histograms\n",
    "        plt.fill_between(bin_centers, offset, counts + offset, color=color, label=f'Epoch {i}', alpha=0.5)\n",
    "\n",
    "    plt.xlabel(\"Pixel accuracy\")\n",
    "    plt.ylabel(\"Epoch ->\")\n",
    "    plt.title(\"Evolution of pixel accuracy\")\n",
    "    plt.yticks([])  # Hide y-ticks since they don't represent absolute values\n",
    "    plt.grid(axis='x')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943c4370",
   "metadata": {},
   "source": [
    "## First experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b3f91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    base_model_path: str = '/home/gbarbadillo/models/Qwen2.5-Coder-0.5B-Instruct'\n",
    "    lora_path: str = '/mnt/hdd0/Kaggle/arc25/trainings/20250430_first_trainings/steps_6400/checkpoint-6400'\n",
    "    prompt_version: str = 'code-from-examples-v3'\n",
    "    grid_encoder = create_grid_encoder('GridShapeEncoder(RowNumberEncoder(MinimalGridEncoder()))')\n",
    "    max_epochs: int = 10\n",
    "    n_predictions: int = 256 # 256 seems to be the best for my hardware"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a87ad6d",
   "metadata": {},
   "source": [
    "### Vertical lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583e5079",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = create_img((9, 9), color=0)\n",
    "output_img = input_img.copy()\n",
    "for x in range(0, input_img.shape[1], 1):\n",
    "    draw_vertical_line(output_img, x, color=x+1)\n",
    "\n",
    "task = Task(inputs=[input_img], outputs=[output_img], code='', name='manual')\n",
    "hindsight_experience_replay(task, Config())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee79972",
   "metadata": {},
   "source": [
    "### Squares"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426a0047",
   "metadata": {},
   "source": [
    "#### 9 squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e5ac0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = create_img((9, 9), color=0)\n",
    "output_img = input_img.copy()\n",
    "color = 0\n",
    "for x in range(0, input_img.shape[1], 3):\n",
    "    for y in range(0, input_img.shape[0], 3):\n",
    "        color += 1\n",
    "        draw_rectangle(output_img, (x, y), (x+2, y+2), color=color)\n",
    "task = Task(inputs=[input_img], outputs=[output_img], code='', name='manual')\n",
    "metrics = hindsight_experience_replay(task, Config())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b720a6",
   "metadata": {},
   "source": [
    "#### 16 squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fa21f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = create_img((8, 8), color=0)\n",
    "output_img = input_img.copy()\n",
    "color = 0\n",
    "for x in range(0, input_img.shape[1], 2):\n",
    "    for y in range(0, input_img.shape[0], 2):\n",
    "        color = (color + 1) % 10\n",
    "        if color == 0: color = 1\n",
    "        draw_rectangle(output_img, (x, y), (x+1, y+1), color=color)\n",
    "task = Task(inputs=[input_img], outputs=[output_img], code='', name='manual')\n",
    "metrics = hindsight_experience_replay(task, Config())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbd0b60",
   "metadata": {},
   "source": [
    "#### 20 squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b59c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = create_img((10, 8), color=0)\n",
    "output_img = input_img.copy()\n",
    "color = 0\n",
    "for x in range(0, input_img.shape[1], 2):\n",
    "    for y in range(0, input_img.shape[0], 2):\n",
    "        color = (color + 1) % 10\n",
    "        if color == 0: color = 1\n",
    "        draw_rectangle(output_img, (x, y), (x+1, y+1), color=color)\n",
    "task = Task(inputs=[input_img], outputs=[output_img], code='', name='manual')\n",
    "metrics = hindsight_experience_replay(task, Config())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba8c102",
   "metadata": {},
   "source": [
    "#### 24 squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94203f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = create_img((10, 10), color=0)\n",
    "output_img = input_img.copy()\n",
    "color = 0\n",
    "for x in range(0, input_img.shape[1], 2):\n",
    "    for y in range(0, input_img.shape[0], 2):\n",
    "        color = (color + 1) % 10\n",
    "        if color == 0: color = 1\n",
    "        draw_rectangle(output_img, (x, y), (x+1, y+1), color=color)\n",
    "task = Task(inputs=[input_img], outputs=[output_img], code='', name='manual')\n",
    "metrics = hindsight_experience_replay(task, Config())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b22a19",
   "metadata": {},
   "source": [
    "### Pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52eb0481",
   "metadata": {},
   "source": [
    "#### 12 pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b264a1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = create_img((3, 4), color=0)\n",
    "output_img = input_img.copy()\n",
    "color = 0\n",
    "for y in range(0, input_img.shape[0], 1):\n",
    "    for x in range(0, input_img.shape[1], 1):\n",
    "        color = (color + 1) % 10\n",
    "        if color == 0: color = 1\n",
    "        draw_pixel(output_img, (y, x), color=color)\n",
    "task = Task(inputs=[input_img], outputs=[output_img], code='', name='manual')\n",
    "plot_task(task)\n",
    "#hindsight_experience_replay(task, Config())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05515864",
   "metadata": {},
   "source": [
    "## Weaker models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731b269f",
   "metadata": {},
   "source": [
    "What if I try weaker models? (Models that have been trained for a shorter time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b00615",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987cfe25",
   "metadata": {},
   "source": [
    "| batch size | inference time(s) | throughput (preds/s) |\n",
    "|------------|-------------------|----------------------|\n",
    "| 1          | 6.4               | 0.2                  |\n",
    "| 4          | 7.4               | 0.5                  |\n",
    "| 16         | 8.5               | 1.9                  |\n",
    "| 64         | 9                 | 7.1                  |\n",
    "| 128        | 10.9              | 11.7                 |\n",
    "| 256        | 15.3              | 16.7                 |\n",
    "| 512        | 30.1              | 17.0                 |\n",
    "\n",
    "A batch size of 256 might be the sweet spot. It takes just twice as making two predictions with batch size 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055461c5",
   "metadata": {},
   "source": [
    "## TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab80f11",
   "metadata": {},
   "source": [
    "- Better progress visualization\n",
    "- Try weaker models\n",
    "- Can I avoid saving results to disk?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f27fee",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arc25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
