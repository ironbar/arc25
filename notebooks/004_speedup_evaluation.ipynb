{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af49d4fb",
   "metadata": {},
   "source": [
    "# Speedup Evaluation set evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3063b899",
   "metadata": {},
   "source": [
    "## Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f1413d",
   "metadata": {},
   "source": [
    "Currently I have 15 hours per week to use Kaggle compute. That is just around 3 evaluations. Maybe I could filter by the tasks that have been solved or are close to be solved and thus speedup evaluation by a factor between 5 and 10."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c153967b",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcd5289",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a92fe4",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a64fae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepaths = glob.glob('/mnt/hdd0/Kaggle/arc25/predictions/evaluation_set/*.json')\n",
    "predictions = []\n",
    "for filepath in filepaths:\n",
    "    with open(filepath, 'r') as f:\n",
    "        predictions.append(json.load(f))\n",
    "print(len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5718db92",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/mnt/hdd0/Kaggle/arc25/data/arc-prize-2025/arc-agi_evaluation_solutions.json', 'r') as f:\n",
    "    solutions = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929bf7f3",
   "metadata": {},
   "source": [
    "### Tasks that were solved at least once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f863d3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks_solved_at_least_once = set()\n",
    "for task_id, outputs in solutions.items():\n",
    "    for idx, output in enumerate(outputs):\n",
    "        for prediction in predictions:\n",
    "            if any(pred == output for pred in prediction[task_id][idx].values()):\n",
    "                tasks_solved_at_least_once.add(task_id)\n",
    "                break\n",
    "len(tasks_solved_at_least_once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6332e6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tasks_solved_at_least_once)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb4289f",
   "metadata": {},
   "source": [
    "There are 22 tasks that have been solved at least once. So in theory the ceiling of the current approach could be around 18%.\n",
    "\n",
    "```\n",
    "{'800d221b', '16b78196', '6e453dd6', '7666fa5d', '38007db0', '53fb4810', '8f3a5a89', '78332cb0', '0934a4d8', '7ed72f31', '136b0064', '981571dc', 'd35bdbdc', 'db0c5428', '2d0172a1', '3a25b0d8', '1818057f', 'aa4ec2a5', '8b9c3697', '71e489b6', '1ae2feb7', '36a08778'}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67e9a3f",
   "metadata": {},
   "source": [
    "I could also compute pixel accuracy metrics, but I believe this is good enough to start."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arc25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
