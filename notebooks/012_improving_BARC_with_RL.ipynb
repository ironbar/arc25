{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc06525e",
   "metadata": {},
   "source": [
    "# Improving BARC induction model with RL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3909fcf6",
   "metadata": {},
   "source": [
    "## Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5422fd4f",
   "metadata": {},
   "source": [
    "Create the code to do RL with the BARC induction model. \n",
    "\n",
    "Once it works it will be moved to a script."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d5276a",
   "metadata": {},
   "source": [
    "## Server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479db853",
   "metadata": {},
   "source": [
    "Before running the notebook launch a server. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c1d6f8",
   "metadata": {},
   "source": [
    "```bash\n",
    "export CUDA_VISIBLE_DEVICES=0; trl vllm-serve --max_model_len 12000 --model /home/gbarbadillo/models/Llama-3.1-ARC-Potpourri-Induction-8B\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a751caa",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d209f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "INFO 09-12 16:42:29 [__init__.py:241] Automatically detected platform cuda.\n",
      "Unsloth: Your Flash Attention 2 installation seems to be broken?\n",
      "A possible explanation is you have a new CUDA version which isn't\n",
      "yet compatible with FA2? Please file a ticket to Unsloth or FA2.\n",
      "We shall now use Xformers instead, which does not have any performance hits!\n",
      "We found this negligible impact by benchmarking on 1x A100.\n",
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\" # 0 is used by the vllm server\n",
    "\n",
    "from unsloth import FastLanguageModel\n",
    "from dataclasses import dataclass\n",
    "from datasets import Dataset\n",
    "\n",
    "from trl import GRPOConfig, GRPOTrainer\n",
    "\n",
    "from arc25.encoders import create_grid_encoder\n",
    "from arc25.utils import load_arc_dataset_with_solutions\n",
    "from arc25.data_augmentation import apply_data_augmentation, get_random_data_augmentation_params\n",
    "from arc25.prompting import create_prompt_from_task\n",
    "# from arc25.collator import get_data_collator\n",
    "from arc25.logging import configure_logging, logging\n",
    "from arc25.parallel_code_execution import run_code_from_predictions\n",
    "\n",
    "configure_logging()\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b93785",
   "metadata": {},
   "source": [
    "## First steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "464e8273",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class cfg:\n",
    "    # base model\n",
    "    model_path: str = \"/home/gbarbadillo/models/Llama-3.1-ARC-Potpourri-Induction-8B\"\n",
    "    load_in_4bit: bool = True\n",
    "    max_seq_length: int = 12000\n",
    "    grid_encoder: str = 'ColorNameEncoder()'\n",
    "    # LoRA\n",
    "    lora_r: int = 16\n",
    "    use_rslora: bool = True\n",
    "    # dataset\n",
    "    dataset_path: str = \"/mnt/hdd0/Kaggle/arc25/data/arc-prize-2024/arc-agi_training_challenges.json\"\n",
    "    output_dir: str = \"/mnt/hdd0/Kaggle/arc25/trainings/2025-09-12-debug-grpo-b/reward-v1\"\n",
    "    # training hyperparameters\n",
    "    max_epochs: int = 1\n",
    "    num_generations: int = 16\n",
    "    training_batch_size: int = 1\n",
    "    learning_rate: float = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4665e0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400 tasks from /mnt/hdd0/Kaggle/arc25/data/arc-prize-2024/arc-agi_training_challenges.json\n"
     ]
    }
   ],
   "source": [
    "dataset = load_arc_dataset_with_solutions(cfg.dataset_path)\n",
    "print(f\"Loaded {len(dataset)} tasks from {cfg.dataset_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a15c51c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.9.4: Fast Llama patching. Transformers: 4.56.1. vLLM: 0.10.1.1.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 3090. Num GPUs = 1. Max memory: 23.568 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.7.1+cu126. CUDA: 8.6. CUDA Toolkit: 12.6. Triton: 3.3.1\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = None. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74c75c97f2a34bfea3380fca8e47627e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-12 16:42:49,454 - arc25.encoders - INFO - create_grid_encoder - Created `ColorNameEncoder()` as grid encoder\n"
     ]
    }
   ],
   "source": [
    "llm, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    cfg.model_path, load_in_4bit=cfg.load_in_4bit,fast_inference=False, max_seq_length=cfg.max_seq_length)\n",
    "grid_encoder = create_grid_encoder(cfg.grid_encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4877175a",
   "metadata": {},
   "source": [
    "Let's create a small dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98c598ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "grpo_dataset = []\n",
    "for task_id in list(dataset.keys())[:10]: # debug with 10 tasks\n",
    "    for _ in range(1):\n",
    "        # params = get_random_data_augmentation_params()\n",
    "        # task = apply_data_augmentation(dataset[task_id], **params)\n",
    "        task = dataset[task_id] # debug without data augmentation\n",
    "        prompt = create_prompt_from_task(\n",
    "                task, grid_encoder=grid_encoder, tokenizer=tokenizer, shuffle_train_samples=True)\n",
    "        grpo_dataset.append(dict(prompt=prompt, tasks=task))\n",
    "grpo_dataset = Dataset.from_list(grpo_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b82b9ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def arc_reward(completions, tasks, completion_ids, **kwargs):\n",
    "    \"\"\"\n",
    "    Reward function that rewards completions based on how many test cases they pass.\n",
    "\n",
    "    As input seems to be receiving: completions, prompts, ground_truth and completion_ids\n",
    "    \"\"\"\n",
    "    results = run_code_from_predictions(tasks, list(range(len(completions))), completions, [None]*len(completions), group_results_by_task=False)\n",
    "    logger.info(f'Completions length: {[len(c) for c in completion_ids]}')\n",
    "    # logger.info(f\"Reward results: {results}\")\n",
    "    # logger.info(f\"Task ids: {[result['task_id'] for result in results]}\") # this verifies that results are in the same order as completions\n",
    "    if 'code' in results[0]:\n",
    "        logger.info(f\"Example code:\\n{results[0]['code']}\")\n",
    "\n",
    "    rewards = []\n",
    "    for result in results:\n",
    "        if 'code' not in result:\n",
    "            rewards.append(-1.0)\n",
    "        elif 'train_correct_grids' not in result:\n",
    "            rewards.append(0.0)\n",
    "        else:\n",
    "            rewards.append(float(result['train_correct_grids']) + float(result.get('test_correct_grids', 0)))\n",
    "\n",
    "    logger.info(f'Rewards: {rewards}')\n",
    "    return rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "082aea15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.9.4 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    llm,\n",
    "    r = cfg.lora_r, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\n",
    "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "        \"gate_proj\", \"up_proj\", \"down_proj\",\n",
    "    ], # Remove QKVO if out of memory\n",
    "    lora_alpha = 64,\n",
    "    use_gradient_checkpointing = \"unsloth\", # Enable long context finetuning\n",
    "    use_rslora = cfg.use_rslora,\n",
    "    # random_state = 3407,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce59b755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: We now expect `per_device_train_batch_size` to be a multiple of `num_generations`.\n",
      "We will change the batch size of 1 to the `num_generations` of 16\n",
      "Training arguments: UnslothGRPOConfig(\n",
      "_n_gpu=1,\n",
      "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "average_tokens_across_devices=False,\n",
      "batch_eval_metrics=False,\n",
      "beta=0.001,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "cache_implementation=None,\n",
      "data_seed=3407,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_persistent_workers=False,\n",
      "dataloader_pin_memory=True,\n",
      "dataloader_prefetch_factor=None,\n",
      "ddp_backend=None,\n",
      "ddp_broadcast_buffers=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "delta=None,\n",
      "disable_dropout=False,\n",
      "disable_tqdm=False,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=False,\n",
      "ds3_gather_for_generation=True,\n",
      "epsilon=0.2,\n",
      "epsilon_high=None,\n",
      "eval_accumulation_steps=2,\n",
      "eval_delay=0,\n",
      "eval_do_concat_batches=True,\n",
      "eval_on_start=False,\n",
      "eval_steps=None,\n",
      "eval_strategy=no,\n",
      "eval_use_gather_object=False,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "generation_batch_size=16,\n",
      "generation_kwargs={},\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=True,\n",
      "gradient_checkpointing_kwargs=None,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_always_push=False,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=None,\n",
      "hub_revision=None,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "importance_sampling_level=token,\n",
      "include_for_metrics=[],\n",
      "include_inputs_for_metrics=False,\n",
      "include_num_input_tokens_seen=False,\n",
      "include_tokens_per_second=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=1e-05,\n",
      "length_column_name=length,\n",
      "liger_kernel_config=None,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=0,\n",
      "log_completions=False,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/mnt/hdd0/Kaggle/arc25/trainings/2025-09-12-debug-grpo-b/reward-v1/runs/Sep12_16-42-54_africanus,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=False,\n",
      "logging_steps=1,\n",
      "logging_strategy=steps,\n",
      "loss_type=bnpo,\n",
      "lr_scheduler_kwargs={},\n",
      "lr_scheduler_type=linear,\n",
      "mask_truncated_completions=False,\n",
      "max_completion_length=1024,\n",
      "max_grad_norm=1.0,\n",
      "max_prompt_length=None,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "min_p=None,\n",
      "model_init_kwargs=None,\n",
      "mp_parameters=,\n",
      "neftune_noise_alpha=None,\n",
      "no_cuda=False,\n",
      "num_completions_to_print=None,\n",
      "num_generations=16,\n",
      "num_iterations=1,\n",
      "num_train_epochs=1,\n",
      "optim=adamw_8bit,\n",
      "optim_args=None,\n",
      "optim_target_modules=None,\n",
      "output_dir=/mnt/hdd0/Kaggle/arc25/trainings/2025-09-12-debug-grpo-b/reward-v1,\n",
      "overwrite_output_dir=None,\n",
      "parallelism_config=None,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=4,\n",
      "per_device_train_batch_size=16,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "ref_model_mixup_alpha=0.6,\n",
      "ref_model_sync_steps=512,\n",
      "remove_unused_columns=False,\n",
      "repetition_penalty=1.0,\n",
      "report_to=['wandb'],\n",
      "restore_callback_states_from_checkpoint=False,\n",
      "resume_from_checkpoint=None,\n",
      "reward_weights=None,\n",
      "run_name=reward-v1,\n",
      "save_on_each_node=False,\n",
      "save_only_model=False,\n",
      "save_safetensors=True,\n",
      "save_steps=500,\n",
      "save_strategy=steps,\n",
      "save_total_limit=None,\n",
      "scale_rewards=group,\n",
      "seed=3407,\n",
      "shuffle_dataset=True,\n",
      "skip_memory_metrics=True,\n",
      "steps_per_generation=1,\n",
      "sync_ref_model=False,\n",
      "temperature=1.0,\n",
      "tf32=None,\n",
      "top_entropy_quantile=1.0,\n",
      "top_k=None,\n",
      "top_p=0.95,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torch_empty_cache_steps=250,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "unsloth_num_chunks=-1,\n",
      "use_cpu=False,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_liger_kernel=False,\n",
      "use_liger_loss=False,\n",
      "use_mps_device=False,\n",
      "use_transformers_paged=False,\n",
      "use_vllm=True,\n",
      "vllm_enable_sleep_mode=False,\n",
      "vllm_gpu_memory_utilization=0.3,\n",
      "vllm_guided_decoding_regex=None,\n",
      "vllm_importance_sampling_cap=2.0,\n",
      "vllm_importance_sampling_correction=False,\n",
      "vllm_mode=server,\n",
      "vllm_model_impl=vllm,\n",
      "vllm_sampling_params=None,\n",
      "vllm_server_base_url=None,\n",
      "vllm_server_host=0.0.0.0,\n",
      "vllm_server_port=8000,\n",
      "vllm_server_timeout=240.0,\n",
      "vllm_tensor_parallel_size=1,\n",
      "wandb_log_unique_prompts=False,\n",
      "warmup_ratio=0.1,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.01,\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# https://huggingface.co/docs/trl/main/en/grpo_trainer#trl.GRPOConfig\n",
    "training_args = GRPOConfig(\n",
    "    output_dir=cfg.output_dir,\n",
    "    num_train_epochs=cfg.max_epochs,\n",
    "    per_device_train_batch_size=cfg.training_batch_size,\n",
    "    num_generations=cfg.num_generations,\n",
    "    gradient_accumulation_steps=1, # how many prompts are used per task\n",
    "    learning_rate=cfg.learning_rate,\n",
    "    # generation\n",
    "    use_vllm=True,\n",
    "    vllm_mode=\"server\",\n",
    "    max_completion_length=1024,\n",
    "    max_prompt_length=None,\n",
    "    temperature=1.0,\n",
    "    top_p=0.95,\n",
    "    # wandb\n",
    "    report_to='wandb',\n",
    "    run_name=os.path.basename(cfg.output_dir),\n",
    "    # project=os.path.basename(os.path.dirname(cfg.output_dir)),\n",
    ")\n",
    "os.environ[\"WANDB_PROJECT\"] = os.path.basename(os.path.dirname(cfg.output_dir))\n",
    "# set also the output dir for wandb\n",
    "os.environ[\"WANDB_DIR\"] = cfg.output_dir\n",
    "\n",
    "print(f\"Training arguments: {training_args}\")\n",
    "# Unsloth: We now expect `per_device_train_batch_size` to be a multiple of `num_generations`. ???\n",
    "# Why ??? I want to use gradient accumulation to simulate larger batch sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f00cc82d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-12 16:42:54,944 - trl.extras.vllm_client - INFO - check_server - Server is up!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 09-12 16:42:55 [__init__.py:1418] Found nccl from library libnccl.so.2\n",
      "INFO 09-12 16:42:55 [pynccl.py:70] vLLM is using nccl==2.26.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 128009}.\n",
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 10 | Num Epochs = 1 | Total steps = 10\n",
      "O^O/ \\_/ \\    Batch size per device = 16 | Gradient accumulation steps = 1\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (16 x 1 x 1) = 16\n",
      " \"-____-\"     Trainable parameters = 41,943,040 of 8,072,204,288 (0.52% trained)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mguillermobarbadillo\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/hdd0/Kaggle/arc25/trainings/2025-09-12-debug-grpo-b/reward-v1/wandb/run-20250912_164257-jxubnvc5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/guillermobarbadillo/2025-09-12-debug-grpo-b/runs/jxubnvc5' target=\"_blank\">reward-v1</a></strong> to <a href='https://wandb.ai/guillermobarbadillo/2025-09-12-debug-grpo-b' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/guillermobarbadillo/2025-09-12-debug-grpo-b' target=\"_blank\">https://wandb.ai/guillermobarbadillo/2025-09-12-debug-grpo-b</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/guillermobarbadillo/2025-09-12-debug-grpo-b/runs/jxubnvc5' target=\"_blank\">https://wandb.ai/guillermobarbadillo/2025-09-12-debug-grpo-b/runs/jxubnvc5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36239d5c71124da28be8ac3c496495cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing predictions:   0%|          | 0/1 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eba7f19049ac4663b8347b4f92d9343f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing predictions for batch 0:   0%|          | 0/16 [00:00<?, ?pred/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-12 16:43:07,133 - __main__ - INFO - arc_reward - Completions length: [240, 264, 244, 232, 269, 245, 241, 231, 271, 237, 240, 269, 240, 237, 239, 251]\n",
      "2025-09-12 16:43:07,135 - __main__ - INFO - arc_reward - Example code:\n",
      "from common import *\n",
      "\n",
      "import numpy as np\n",
      "from typing import *\n",
      "\n",
      "# concepts:\n",
      "# sorting, height mapping, color assignment\n",
      "\n",
      "# description:\n",
      "# In the input you will see a row of exactly 4 gray bars of different heights, each starting at the bottom of the canvas, and each separated by 1 pixel (so they are two pixels apart).\n",
      "# Color the tallest one blue, the second tallest one red, the third tallest one green, and the shortest one yellow.\n",
      "\n",
      "def transform(input_grid):\n",
      "    # extract the bars, each of which is a connected component\n",
      "    bars = find_connected_components(input_grid, background=Color.BLACK)\n",
      "\n",
      "    # sort the bars by height\n",
      "    bars = list(sorted(bars, key=lambda bar: np.sum(bar!= Color.BLACK), reverse=True))\n",
      "\n",
      "    # color the bars\n",
      "    output_grid = input_grid.copy()\n",
      "\n",
      "    # Assign colors based on sorted height\n",
      "    colors = [Color.BLUE, Color.RED, Color.GREEN, Color.YELLOW]\n",
      "    \n",
      "    for i, bar in enumerate(bars):\n",
      "        bar_mask = bar!= Color.BLACK\n",
      "        output_grid[bar_mask] = colors[i]\n",
      "\n",
      "    return output_grid\n",
      "2025-09-12 16:43:07,136 - __main__ - INFO - arc_reward - Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 07:13, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>reward</th>\n",
       "      <th>reward_std</th>\n",
       "      <th>completions / mean_length</th>\n",
       "      <th>completions / min_length</th>\n",
       "      <th>completions / max_length</th>\n",
       "      <th>completions / clipped_ratio</th>\n",
       "      <th>completions / mean_terminated_length</th>\n",
       "      <th>completions / min_terminated_length</th>\n",
       "      <th>completions / max_terminated_length</th>\n",
       "      <th>sampling / sampling_logp_difference / mean</th>\n",
       "      <th>sampling / sampling_logp_difference / max</th>\n",
       "      <th>sampling / importance_sampling_ratio / min</th>\n",
       "      <th>sampling / importance_sampling_ratio / mean</th>\n",
       "      <th>sampling / importance_sampling_ratio / max</th>\n",
       "      <th>kl</th>\n",
       "      <th>rewards / arc_reward / mean</th>\n",
       "      <th>rewards / arc_reward / std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>246.875000</td>\n",
       "      <td>231.000000</td>\n",
       "      <td>271.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>246.875000</td>\n",
       "      <td>231.000000</td>\n",
       "      <td>271.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>211.687500</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>247.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>211.687500</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>247.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>293.062500</td>\n",
       "      <td>222.000000</td>\n",
       "      <td>457.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>293.062500</td>\n",
       "      <td>222.000000</td>\n",
       "      <td>457.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>402.000000</td>\n",
       "      <td>333.000000</td>\n",
       "      <td>575.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>402.000000</td>\n",
       "      <td>333.000000</td>\n",
       "      <td>575.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>368.312500</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>474.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>368.312500</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>474.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>323.875000</td>\n",
       "      <td>251.000000</td>\n",
       "      <td>385.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>323.875000</td>\n",
       "      <td>251.000000</td>\n",
       "      <td>385.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>502.125000</td>\n",
       "      <td>329.000000</td>\n",
       "      <td>795.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>502.125000</td>\n",
       "      <td>329.000000</td>\n",
       "      <td>795.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>389.437500</td>\n",
       "      <td>244.000000</td>\n",
       "      <td>593.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>389.437500</td>\n",
       "      <td>244.000000</td>\n",
       "      <td>593.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>437.875000</td>\n",
       "      <td>230.000000</td>\n",
       "      <td>619.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>437.875000</td>\n",
       "      <td>230.000000</td>\n",
       "      <td>619.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>283.312500</td>\n",
       "      <td>186.000000</td>\n",
       "      <td>433.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>283.312500</td>\n",
       "      <td>186.000000</td>\n",
       "      <td>433.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ffb8e03e3714795b5e389c385b22968",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing predictions:   0%|          | 0/1 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19ef7b75e840436fa30011d913428ad8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing predictions for batch 0:   0%|          | 0/16 [00:00<?, ?pred/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-12 16:43:32,918 - __main__ - INFO - arc_reward - Completions length: [195, 218, 247, 202, 212, 206, 240, 240, 223, 226, 218, 205, 175, 186, 194, 200]\n",
      "2025-09-12 16:43:32,920 - __main__ - INFO - arc_reward - Example code:\n",
      "from common import *\n",
      "\n",
      "import numpy as np\n",
      "from typing import *\n",
      "\n",
      "# concepts:\n",
      "# topology, object boundary, region filling\n",
      "\n",
      "# description:\n",
      "# The input grid consists of a black background with some green pixels forming a closed shape. \n",
      "# To produce the output, you need to find the boundary of the closed shape and color the enclosed area yellow. \n",
      "# The output should retain the original boundary pixels but fill the interior with yellow.\n",
      "\n",
      "def transform(input_grid):\n",
      "    # Create an output grid initialized to black\n",
      "    output_grid = np.copy(input_grid)\n",
      "\n",
      "    # Find the boundary of the object\n",
      "    boundary_mask = object_boundary(input_grid, background=Color.BLACK)\n",
      "\n",
      "    # Create an interior mask for the region that is not on the boundary\n",
      "    interior_mask = object_interior(input_grid)\n",
      "\n",
      "    # Fill the interior with yellow\n",
      "    output_grid[interior_mask & ~boundary_mask] = Color.YELLOW\n",
      "\n",
      "    return output_grid\n",
      "2025-09-12 16:43:32,922 - __main__ - INFO - arc_reward - Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fa7d53788d34aed8674724a4dba675b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing predictions:   0%|          | 0/1 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91171033cbc84585ac774f637cb1d48e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing predictions for batch 0:   0%|          | 0/16 [00:00<?, ?pred/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-12 16:44:24,654 - __main__ - INFO - arc_reward - Completions length: [335, 224, 285, 293, 369, 327, 236, 294, 241, 457, 275, 270, 222, 290, 287, 284]\n",
      "2025-09-12 16:44:24,656 - __main__ - INFO - arc_reward - Example code:\n",
      "from common import *\n",
      "import numpy as np\n",
      "from typing import *\n",
      "\n",
      "# concepts:\n",
      "# bitmasks with separator, boolean logical operations\n",
      "\n",
      "# description:\n",
      "# Compute the AND operation of where the two grids are blue, turning the output red in those locations.\n",
      "# In the input, you should see two 3x3 blue patterns on top and bottom separated by a horizontal gray line in the middle of the grid.\n",
      "# To make the output, you have to overlap the two patterns. If both overlapping cells are blue, then the corresponding cell is colored red; \n",
      "# otherwise, if the overlapping cells are not both blue, then the corresponding cell is colored black.\n",
      "\n",
      "def transform(input_grid):\n",
      "    # Get the height and width of the input grid\n",
      "    width, height = input_grid.shape\n",
      "\n",
      "    # Find the gray horizontal line/bar\n",
      "    for y_bar in range(height):\n",
      "        if np.all(input_grid[:, y_bar] == Color.GRAY):\n",
      "            break\n",
      "    \n",
      "    # Extract top and bottom patterns\n",
      "    top_pattern = input_grid[:, :y_bar]\n",
      "    bottom_pattern = input_grid[:, y_bar + 1:]\n",
      "\n",
      "    output_grid = np.zeros_like(top_pattern)\n",
      "\n",
      "    # Applying the AND pattern, which is where both are blue\n",
      "    output_grid = np.zeros_like(top_pattern)\n",
      "\n",
      "    # Set red where both are blue and so forth\n",
      "    output_grid[(top_pattern == Color.BLUE) & (bottom_pattern == Color.BLUE)] = Color.RED\n",
      "    # Fill the rest with black\n",
      "    output_grid[(top_pattern!= Color.BLUE) | (bottom_pattern!= Color.BLUE)] = Color.BLACK\n",
      "\n",
      "    return output_grid\n",
      "2025-09-12 16:44:24,657 - __main__ - INFO - arc_reward - Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8676c98219b447a78879642e31ebf546",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing predictions:   0%|          | 0/1 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c686342e6e64549a5b75524bf9b5871",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing predictions for batch 0:   0%|          | 0/16 [00:00<?, ?pred/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-12 16:44:53,336 - __main__ - INFO - arc_reward - Completions length: [386, 333, 371, 367, 336, 384, 340, 343, 406, 407, 514, 349, 534, 575, 422, 365]\n",
      "2025-09-12 16:44:53,338 - __main__ - INFO - arc_reward - Example code:\n",
      "from common import *\n",
      "\n",
      "import numpy as np\n",
      "from typing import *\n",
      "\n",
      "# concepts:\n",
      "# sliding objects, collision detection\n",
      "\n",
      "# description:\n",
      "# In the input you will see a 2x2 purple square and a set of red objects. \n",
      "# Slide each red object in any of the four directions until it just touches the purple square.\n",
      "\n",
      "def transform(input_grid):\n",
      "    # Get the purple object\n",
      "    purple_object = np.zeros_like(input_grid)\n",
      "    purple_object[input_grid == Color.PURPLE] = Color.PURPLE\n",
      "\n",
      "    # Get the red objects\n",
      "    red_objects = detect_objects(grid=input_grid, colors=[Color.RED], monochromatic=False, connectivity=4)\n",
      "    \n",
      "    # Start the output grid with just the purple object\n",
      "    output_grid = np.copy(purple_object)\n",
      "\n",
      "    # Slide each red object until it touches the purple square\n",
      "    for red_object in red_objects:\n",
      "        # Consider translating the red object in the 4 cardinal directions\n",
      "        possible_displacements = [(slide_distance * dx, slide_distance * dy)\n",
      "                                   for slide_distance in range(max(input_grid.shape))\n",
      "                                   for dx, dy in [(0, 1), (0, -1), (1, 0), (-1, 0)]]\n",
      "        for x, y in possible_displacements:\n",
      "            # Check if the red object touches the purple object after sliding\n",
      "            translated_red_object = translate(red_object, x, y, background=Color.BLACK)\n",
      "            if contact(object1=purple_object, object2=translated_red_object):\n",
      "                # Blit the red object onto the output grid\n",
      "                blit_object(output_grid, translated_red_object, background=Color.BLACK)\n",
      "                break\n",
      "        else:\n",
      "            # If no contact found, just blit to the last position\n",
      "            blit_object(output_grid, red_object, background=Color.BLACK)\n",
      "\n",
      "    return output_grid\n",
      "2025-09-12 16:44:53,339 - __main__ - INFO - arc_reward - Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e76f97ef52074d8c98f0fc149066cd23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing predictions:   0%|          | 0/1 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a78f131a376e4df09c2970dde9e32d98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing predictions for batch 0:   0%|          | 0/16 [00:00<?, ?pred/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-12 16:45:32,307 - __main__ - INFO - arc_reward - Completions length: [423, 470, 178, 424, 310, 474, 464, 361, 274, 187, 368, 474, 351, 275, 388, 472]\n",
      "2025-09-12 16:45:32,309 - __main__ - INFO - arc_reward - Example code:\n",
      "from common import *\n",
      "\n",
      "import numpy as np\n",
      "from typing import *\n",
      "\n",
      "# concepts:\n",
      "# color gradient, scaling\n",
      "\n",
      "# description:\n",
      "# In the input, you will see a small colored shape in the center of the grid. The shape has a color gradient from the center to the edges. \n",
      "# To create the output, scale the shape up by a factor of 2 while maintaining the color gradient, ensuring that the gradient smoothly transitions from the center outwards.\n",
      "\n",
      "def transform(input_grid):\n",
      "    # Detect the colored shape in the center of the grid\n",
      "    objects = detect_objects(grid=input_grid, monochromatic=False, background=Color.BLACK, connectivity=8)\n",
      "\n",
      "    # Initialize the output grid with the same size as the input grid\n",
      "    output_grid = np.zeros_like(input_grid)\n",
      "\n",
      "    for obj in objects:\n",
      "        # Crop the object to produce a sprite\n",
      "        sprite = crop(obj, background=Color.BLACK)\n",
      "\n",
      "        # Get the center of the sprite\n",
      "        center_x, center_y = sprite.shape[0] // 2, sprite.shape[1] // 2\n",
      "\n",
      "        # Calculate the new size for the output shape\n",
      "        new_size = (sprite.shape[0] * 2, sprite.shape[1] * 2)\n",
      "        scaled_sprite = np.zeros(new_size, dtype=int)\n",
      "\n",
      "        # Scale up the sprite while maintaining the color gradient\n",
      "        for x in range(sprite.shape[0]):\n",
      "            for y in range(sprite.shape[1]):\n",
      "                color = input_grid[x, y]\n",
      "                # Calculate the distance from the center point to determine the gradient effect\n",
      "                distance = np.sqrt((x - center_x) ** 2 + (y - center_y) ** 2)\n",
      "                # Apply the color based on the distance from the center\n",
      "                scaled_sprite[x, y] = color if distance < center_x else Color.BLACK\n",
      "\n",
      "        # Blit the scaled sprite onto the output grid\n",
      "        blit_sprite(output_grid, scaled_sprite, x=0, y=0, background=Color.BLACK)\n",
      "\n",
      "    return output_grid\n",
      "2025-09-12 16:45:32,311 - __main__ - INFO - arc_reward - Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80b0d4da69884e2e8e9d0e14ffd1c2f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing predictions:   0%|          | 0/1 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3b7e4fe7cd34bc98650691b3e8cecf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing predictions for batch 0:   0%|          | 0/16 [00:00<?, ?pred/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-12 16:46:02,437 - __main__ - INFO - arc_reward - Completions length: [326, 335, 324, 358, 328, 374, 307, 294, 318, 251, 300, 309, 301, 331, 341, 385]\n",
      "2025-09-12 16:46:02,439 - __main__ - INFO - arc_reward - Example code:\n",
      "from common import *\n",
      "\n",
      "import numpy as np\n",
      "from typing import *\n",
      "\n",
      "# concepts:\n",
      "# reflection, color change, symmetry detection\n",
      "\n",
      "# description:\n",
      "# In the input, you will see a grid containing a pattern of blue pixels arranged in a way that exhibits translational symmetry.\n",
      "# To create the output, reflect this pattern horizontally and change the color from blue to red. \n",
      "# The output grid should be large enough to accommodate the original pattern and its reflection.\n",
      "\n",
      "def transform(input_grid):\n",
      "    # Detect translational symmetries in the input grid\n",
      "    symmetries = detect_translational_symmetry(input_grid, ignore_colors=[Color.BLACK])\n",
      "    assert len(symmetries) > 0, \"No translational symmetry found\"\n",
      "\n",
      "    # Create a new output grid with double the height to accommodate the original and the reflected pattern\n",
      "    output_grid = np.full((input_grid.shape[0] * 2, input_grid.shape[1]), Color.BLACK)\n",
      "\n",
      "    # Copy the original pattern into the output grid\n",
      "    for x, y in np.argwhere(input_grid!= Color.BLACK):\n",
      "        output_grid[x, y] = input_grid[x, y]\n",
      "\n",
      "    # Reflect the original pattern and change the color from blue to red\n",
      "    for x, y in np.argwhere(input_grid!= Color.BLACK):\n",
      "        if input_grid[x, y] == Color.BLUE:\n",
      "            reflected_x = x + input_grid.shape[0]  # Shift the reflected pattern down by the height of the grid\n",
      "            output_grid[reflected_x, y] = Color.RED\n",
      "    \n",
      "    return output_grid\n",
      "2025-09-12 16:46:02,441 - __main__ - INFO - arc_reward - Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff761b0f179c41ef90349742e3bc1355",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing predictions:   0%|          | 0/1 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef7c551881b343cba7b57d4710adbc83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing predictions for batch 0:   0%|          | 0/16 [00:00<?, ?pred/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-12 16:46:39,318 - __main__ - INFO - arc_reward - Completions length: [368, 476, 481, 482, 662, 599, 495, 329, 795, 431, 682, 521, 448, 385, 409, 471]\n",
      "2025-09-12 16:46:39,321 - __main__ - INFO - arc_reward - Example code:\n",
      "from common import *\n",
      "import numpy as np\n",
      "from typing import *\n",
      "\n",
      "# concepts:\n",
      "# grid manipulation, regions, overlapping colors, color transformation\n",
      "\n",
      "# description:\n",
      "# In the input, you will see a grid divided by horizontal and vertical lines, forming rectangular regions. \n",
      "# Each region can contain colored pixels, and there are also special colored pixels (red and green).\n",
      "# To make the output:\n",
      "# 1. For each red pixel, fill the entire region it's in with the same color.\n",
      "# 2. For each green pixel, fill the entire region it's in with the same color, but only if that region is not already filled with red.\n",
      "\n",
      "def transform(input_grid: np.ndarray) -> np.ndarray:\n",
      "    output_grid = np.copy(input_grid)\n",
      "\n",
      "    # Find the divider color (assuming it's the most frequent non-background color)\n",
      "    divider_color = max(Color.NOT_BLACK, key=lambda color: np.sum(input_grid == color))\n",
      "\n",
      "    # Get connected components of regions, treating the divider color as the background\n",
      "    regions = find_connected_components(input_grid, background=divider_color, monochromatic=False)\n",
      "\n",
      "    for region in regions:\n",
      "        # Determine the colors present in the region\n",
      "        colors_in_region = object_colors(region, background=divider_color)\n",
      "        \n",
      "        # Check for red and green pixels in the region\n",
      "        has_red = Color.RED in colors_in_region\n",
      "        has_green = Color.GREEN in colors_in_region\n",
      "\n",
      "        # If there's red, fill the whole region with red\n",
      "        if has_red:\n",
      "            output_grid[region!= divider_color] = Color.RED\n",
      "\n",
      "        # If there's green and no red, fill the region with green\n",
      "        elif has_green:\n",
      "            output_grid[region!= divider_color] = Color.GREEN\n",
      "\n",
      "    return output_grid\n",
      "2025-09-12 16:46:39,323 - __main__ - INFO - arc_reward - Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5661ccac3fa546aab8b3c250dac2fe65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing predictions:   0%|          | 0/1 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb6d66bed8844f939c6d4d0cf9d20c1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing predictions for batch 0:   0%|          | 0/16 [00:00<?, ?pred/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-12 16:48:19,489 - __main__ - INFO - arc_reward - Completions length: [418, 380, 294, 469, 254, 593, 443, 354, 244, 388, 260, 502, 396, 472, 441, 323]\n",
      "2025-09-12 16:48:19,491 - __main__ - INFO - arc_reward - Example code:\n",
      "from common import *\n",
      "\n",
      "import numpy as np\n",
      "from typing import *\n",
      "\n",
      "# concepts:\n",
      "# repetition, diagonal lines\n",
      "\n",
      "# description:\n",
      "# In the input you will see a 7x7 grid with three diagonal lines that stretch from one corner of the canvas to the other.\n",
      "# Each line is a different color, and the colors are not black. The output should be the result of repeating every diagonal line\n",
      "# on multiples of 2 offset from the original, which gives an interlacing pattern filling the output canvas.\n",
      "\n",
      "def transform(input_grid: np.ndarray) -> np.ndarray:\n",
      "    output_grid = np.zeros((7, 7), dtype=int)\n",
      "\n",
      "    # Loop over the input grid to find diagonal lines\n",
      "    for i in range(input_grid.shape[0]):\n",
      "        for j in range(input_grid.shape[1]):\n",
      "            c = input_grid[i][j]\n",
      "            if c!= Color.BLACK:\n",
      "                # Draw the diagonal lines at multiples of 2\n",
      "                for distance in range(-2, 8, 2):  # Loop to cover all necessary positions\n",
      "                    # Draw lines in both diagonal directions\n",
      "                    draw_diagonal(output_grid, i + distance, j, c)\n",
      "                    draw_diagonal(output_grid, i - distance, j, c)\n",
      "\n",
      "    return output_grid\n",
      "\n",
      "def draw_diagonal(grid, i, j, color):\n",
      "    # Draw a diagonal line from one corner of the grid\n",
      "    draw_line(grid, j, i, color=j, direction=(1, 1), color=j)\n",
      "\n",
      "def draw_diagonal(grid, i, j, color):\n",
      "    draw_line(grid, 0, j, color=i, direction=(1, 1), color=j)\n",
      "    draw_line(grid, j, i, color=color, direction=(-1, 1), color=j)\n",
      "\n",
      "def draw_line(grid, x, y, direction, color):\n",
      "    # Draw a line from (x, y) in the direction specified\n",
      "    draw_line(grid, x, y, length=None, color=color, direction=direction)\n",
      "2025-09-12 16:48:19,494 - __main__ - INFO - arc_reward - Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07c0154239a44f31843237526905091c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing predictions:   0%|          | 0/1 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8022242f93d46caafcac13dc4f9a376",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing predictions for batch 0:   0%|          | 0/16 [00:00<?, ?pred/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-12 16:48:57,942 - __main__ - INFO - arc_reward - Completions length: [559, 421, 470, 230, 380, 619, 525, 571, 402, 428, 585, 442, 253, 362, 274, 485]\n",
      "2025-09-12 16:48:57,944 - __main__ - INFO - arc_reward - Example code:\n",
      "from common import *\n",
      "\n",
      "import numpy as np\n",
      "from typing import *\n",
      "\n",
      "# concepts:\n",
      "# translation, color swapping, pattern arrangement\n",
      "\n",
      "# description:\n",
      "# In the input, you will see a grid with a central square pattern and several colored rectangles surrounding it.\n",
      "# To create the output, swap the colors of the central square with each surrounding rectangle, then move the rectangles outward in all four cardinal directions until they touch the edges of the grid.\n",
      "\n",
      "def transform(input_grid: np.ndarray) -> np.ndarray:\n",
      "    # Step 1: Find the central square and surrounding rectangles\n",
      "    objects = find_connected_components(input_grid, monochromatic=False)\n",
      "    \n",
      "    # Identify the central square (assumed to be the largest connected component)\n",
      "    central_square = max(objects, key=lambda obj: np.sum(obj!= Color.BLACK))\n",
      "    \n",
      "    # Create a copy of the input grid for the output\n",
      "    output_grid = np.copy(input_grid)\n",
      "\n",
      "    # Get the colors of the central square\n",
      "    central_color = central_square[central_square!= Color.BLACK][0]\n",
      "\n",
      "    # Step 2: Swap colors between the central square and surrounding rectangles\n",
      "    for obj in objects:\n",
      "        if not np.array_equal(obj, central_square):\n",
      "            # Get the color of the current rectangle\n",
      "            rectangle_color = obj[obj!= Color.BLACK][0]\n",
      "\n",
      "            # Swap colors in the output grid\n",
      "            output_grid = np.copy(output_grid)\n",
      "            output_grid = np.where(input_grid == rectangle_color, rectangle_color, output_grid)\n",
      "            output_grid = np.where(input_grid == central_color, central_color, output_grid)\n",
      "            output_grid = np.where(input_grid == central_color, rectangle_color, input_grid)\n",
      "            output_grid = np.where(input_grid == rectangle_color, rectangle_color, input_grid)\n",
      "\n",
      "    # Step 3: Move the rectangles outward in all four cardinal directions until they hit the grid edges\n",
      "    output_grid = np.copy(input_grid)\n",
      "\n",
      "    # Step 4: Repeat the pattern to fill the grid\n",
      "    for rectangle in objects:\n",
      "        if not np.array_equal(rectangle, central_square):\n",
      "            color = rectangle[rectangle!= Color.BLACK][0]\n",
      "            # Move the rectangle in all four directions until it hits the edges\n",
      "            for dx, dy in [(0, 1), (0, -1), (1, 0), (-1, 0)]:\n",
      "                translated_rectangle = translate(rectangle, dx, dy)\n",
      "                if (0 <= translated_rectangle.shape[0] < output_grid.shape[0] and\n",
      "                    0 <= translated_rectangle.shape[1] < output_grid.shape[1]):\n",
      "                    blit_sprite(output_grid, translated_rectangle, x=0, y=0, background=Color.BLACK)\n",
      "\n",
      "    return output_grid\n",
      "2025-09-12 16:48:57,946 - __main__ - INFO - arc_reward - Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46908ed229194036963afbe24004c5a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing predictions:   0%|          | 0/1 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2c913d0a09645a0b6f8bdbec7e3e2cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing predictions for batch 0:   0%|          | 0/16 [00:00<?, ?pred/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-12 16:50:17,671 - __main__ - INFO - arc_reward - Completions length: [329, 228, 365, 239, 326, 254, 277, 433, 217, 300, 228, 394, 302, 214, 186, 241]\n",
      "2025-09-12 16:50:17,673 - __main__ - INFO - arc_reward - Example code:\n",
      "from common import *\n",
      "\n",
      "import numpy as np\n",
      "from typing import *\n",
      "\n",
      "# concepts:\n",
      "# scaling, pattern replication, color mapping\n",
      "\n",
      "# description:\n",
      "# In the input you will see a 3x3 pattern of colored pixels.\n",
      "# To create the output, scale the pattern to a 9x9 grid by replicating it three times in each direction,\n",
      "# and then map the colors of the original pattern to the new scaled positions using a color mapping that \n",
      "# shifts the colors by one position in a cyclic manner.\n",
      "\n",
      "def transform(input_grid):\n",
      "    # Get the color mapping by extracting the unique colors in the 3x3 pattern\n",
      "    unique_colors = np.unique(input_grid)\n",
      "    color_mapping = {color: (unique_colors[(i + 1) % len(unique_colors)]) for i, color in enumerate(unique_colors)}\n",
      "\n",
      "    # Create the output grid initialized to black\n",
      "    output_grid = np.full((9, 9), Color.BLACK)\n",
      "\n",
      "    # Scale the pattern by replicating it in a 3x3 grid\n",
      "    for i in range(3):\n",
      "        for j in range(3):\n",
      "            # Get the original color\n",
      "            original_color = input_grid[i, j]\n",
      "            # Map the color using the color mapping\n",
      "            new_color = color_mapping.get(original_color, original_color)\n",
      "            # Place the new color in the corresponding scaled position\n",
      "            output_grid[i * 3 + i:i * 3 + (i + 1), j * 3 + j:j * 3 + (j + 1)] = new_color\n",
      "\n",
      "    return output_grid\n",
      "2025-09-12 16:50:17,674 - __main__ - INFO - arc_reward - Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=10, training_loss=0.0, metrics={'train_runtime': 461.4252, 'train_samples_per_second': 0.022, 'train_steps_per_second': 0.022, 'total_flos': 0.0, 'train_loss': 0.0})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = GRPOTrainer(\n",
    "    model=model,\n",
    "    reward_funcs=arc_reward, #reward_num_unique_letters,\n",
    "    # data_collator=get_data_collator(tokenizer),\n",
    "    args=training_args,\n",
    "    train_dataset=grpo_dataset,\n",
    "    completion_only_loss=True,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1033069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this to reset the vllm server\n",
    "# ! curl  -X POST --location http://0.0.0.0:8000/close_communicator/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c8ab6a",
   "metadata": {},
   "source": [
    "## Debug"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c47195",
   "metadata": {},
   "source": [
    "There seem to be some compatibility problems:\n",
    "\n",
    "```\n",
    "This happens when creating the training conf:\n",
    "Unsloth: We now expect `per_device_train_batch_size` to be a multiple of `num_generations`. ???\n",
    "\n",
    "This happens when training\n",
    "AttributeError: 'UnslothGRPOConfig' object has no attribute 'delta'\n",
    "\n",
    "Library versions:\n",
    "unsloth                   2025.9.1                 pypi_0    pypi\n",
    "unsloth-zoo               2025.9.2                 pypi_0    pypi\n",
    "trl                       0.18.0.dev0              pypi_0    pypi\n",
    "\n",
    "# pip index versions <package-name>\n",
    "unsloth (2025.9.4)\n",
    "Available versions: 2025.9.4, 2025.9.3, 2025.9.2, 2025.9.1,\n",
    "trl (0.23.0)\n",
    "Available versions: 0.23.0, 0.22.2, 0.22.1, 0.22.0, 0.21.0, 0.20.0, 0.19.1, 0.19.0, 0.18.2, 0.18.1, 0.18.0\n",
    "\n",
    "I have installed the latest versions of both libraries on the environment `arc25-unsloth`\n",
    "pip install unsloth==2025.9.4\n",
    "pip install trl==0.23.0\n",
    "pip install trl[vllm]\n",
    "\n",
    "Then it gives this error when launching the server.\n",
    "NameError: name 'ParallelismConfig' is not defined. Did you mean: 'parallelism_config'?\n",
    "Solved with: pip install --upgrade accelerate\n",
    "\n",
    "I also have to remove the collator.\n",
    "```\n",
    "\n",
    "This is working, but only did one training step.\n",
    "\n",
    "```\n",
    "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
    "   \\\\   /|    Num examples = 10 | Num Epochs = 1 | Total steps = 1\n",
    "O^O/ \\_/ \\    Batch size per device = 8 | Gradient accumulation steps = 8\n",
    "\\        /    Data Parallel GPUs = 1 | Total batch size (8 x 8 x 1) = 64\n",
    " \"-____-\"     Trainable parameters = 41,943,040 of 8,072,204,288 (0.52% trained)\n",
    "```\n",
    "\n",
    "If I reduce the gradient accumulation steps to 1, increase the number of epochs to 3 then it does 30 steps.\n",
    "\n",
    "Now the problem is that it seems that only be predicting 256 output tokens.\n",
    "\n",
    "Notice "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3060fb",
   "metadata": {},
   "source": [
    "So far I hasn't solved any of the training tasks, but seems to be always predicting the code correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4717522",
   "metadata": {},
   "source": [
    "## TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4a4e7f",
   "metadata": {},
   "source": [
    "- [ ] Implement the reward function\n",
    "- [ ] Check if memory is enough\n",
    "- [ ] Can I optimize the bouncing in compute between the two gpus?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arc25-unsloth",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
