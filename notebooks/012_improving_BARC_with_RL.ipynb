{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc06525e",
   "metadata": {},
   "source": [
    "# Improving BARC induction model with RL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3909fcf6",
   "metadata": {},
   "source": [
    "## Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5422fd4f",
   "metadata": {},
   "source": [
    "Create the code to do RL with the BARC induction model. \n",
    "\n",
    "Once it works it will be moved to a script."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d5276a",
   "metadata": {},
   "source": [
    "## Server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479db853",
   "metadata": {},
   "source": [
    "Before running the notebook launch a server. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c1d6f8",
   "metadata": {},
   "source": [
    "```bash\n",
    "export CUDA_VISIBLE_DEVICES=0; trl vllm-serve --max_model_len 12000 --model /home/gbarbadillo/models/Llama-3.1-ARC-Potpourri-Induction-8B\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a751caa",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d209f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\" # 0 is used by the vllm server\n",
    "\n",
    "from unsloth import FastLanguageModel\n",
    "from dataclasses import dataclass\n",
    "from datasets import Dataset\n",
    "\n",
    "from trl import GRPOConfig, GRPOTrainer\n",
    "\n",
    "from arc25.encoders import create_grid_encoder\n",
    "from arc25.utils import load_arc_dataset_with_solutions\n",
    "from arc25.data_augmentation import apply_data_augmentation, get_random_data_augmentation_params\n",
    "from arc25.prompting import create_prompt_from_task\n",
    "from arc25.collator import get_data_collator\n",
    "from arc25.logging import configure_logging, logging\n",
    "\n",
    "configure_logging()\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b93785",
   "metadata": {},
   "source": [
    "## First steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464e8273",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class cfg:\n",
    "    # base model\n",
    "    model_path: str = \"/home/gbarbadillo/models/Llama-3.1-ARC-Potpourri-Induction-8B\"\n",
    "    load_in_4bit: bool = False\n",
    "    max_seq_length: int = 12000\n",
    "    grid_encoder: str = 'ColorNameEncoder()'\n",
    "    # LoRA\n",
    "    lora_r: int = 16\n",
    "    use_rslora: bool = True\n",
    "    # dataset\n",
    "    dataset_path: str = \"/mnt/hdd0/Kaggle/arc25/data/arc-prize-2024/arc-agi_training_challenges.json\"\n",
    "    output_dir: str = \"/mnt/hdd0/Kaggle/arc25/trainings/2025-09-12-debug-grpo/first-steps\"\n",
    "    # training hyperparameters\n",
    "    max_epochs: int = 1\n",
    "    num_generations: int = 8\n",
    "    training_batch_size: int = 1\n",
    "    learning_rate: float = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4665e0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_arc_dataset_with_solutions(cfg.dataset_path)\n",
    "print(f\"Loaded {len(dataset)} tasks from {cfg.dataset_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15c51c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    cfg.model_path, load_in_4bit=cfg.load_in_4bit,fast_inference=False)\n",
    "grid_encoder = create_grid_encoder(cfg.grid_encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4877175a",
   "metadata": {},
   "source": [
    "Let's create a small dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c598ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_id = list(dataset.keys())[0]\n",
    "grpo_dataset = []\n",
    "for _ in range(10):\n",
    "    params = get_random_data_augmentation_params()\n",
    "    task = apply_data_augmentation(dataset[task_id], **params)\n",
    "    prompt = create_prompt_from_task(\n",
    "            task, grid_encoder=grid_encoder, tokenizer=tokenizer, shuffle_train_samples=True)\n",
    "    ground_truth = [sample['output'] for sample in task['train']] + [sample['output'] for sample in task['test']]\n",
    "    grpo_dataset.append(dict(prompt=prompt, ground_truth=ground_truth))\n",
    "grpo_dataset = Dataset.from_list(grpo_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf316c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_num_unique_letters(completions, **kwargs):\n",
    "    \"\"\"Reward function that rewards completions with more unique letters.\"\"\"\n",
    "    logger.info(f\"Computing reward for {len(completions)} completions\")\n",
    "    logger.info(f'Completions: {completions}')\n",
    "    logger.info(f'This are the kwargs: {list(kwargs.keys())}')\n",
    "    completion_contents = [completion[0][\"content\"] for completion in completions]\n",
    "    return [float(len(set(content))) for content in completion_contents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082aea15",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    llm,\n",
    "    r = cfg.lora_r, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\n",
    "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "        \"gate_proj\", \"up_proj\", \"down_proj\",\n",
    "    ], # Remove QKVO if out of memory\n",
    "    lora_alpha = 64,\n",
    "    use_gradient_checkpointing = \"unsloth\", # Enable long context finetuning\n",
    "    use_rslora = cfg.use_rslora,\n",
    "    # random_state = 3407,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00cc82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = GRPOConfig(\n",
    "    output_dir=cfg.output_dir,\n",
    "    num_train_epochs=cfg.max_epochs,\n",
    "    per_device_train_batch_size=cfg.training_batch_size,\n",
    "    num_generations=cfg.num_generations,\n",
    "    gradient_accumulation_steps=cfg.num_generations // cfg.training_batch_size,\n",
    "    learning_rate=cfg.learning_rate,\n",
    "    use_vllm=True,\n",
    "    vllm_mode=\"server\",\n",
    ")\n",
    "print(f\"Training arguments: {training_args}\")\n",
    "trainer = GRPOTrainer(\n",
    "    model=model,\n",
    "    reward_funcs=reward_num_unique_letters,\n",
    "    data_collator=get_data_collator(tokenizer),\n",
    "    args=training_args,\n",
    "    train_dataset=grpo_dataset,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c8ab6a",
   "metadata": {},
   "source": [
    "## Debug"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4717522",
   "metadata": {},
   "source": [
    "## TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abf46a3",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arc25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
