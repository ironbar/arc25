{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc06525e",
   "metadata": {},
   "source": [
    "# Improving BARC induction model with RL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3909fcf6",
   "metadata": {},
   "source": [
    "## Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5422fd4f",
   "metadata": {},
   "source": [
    "Create the code to do RL with the BARC induction model. \n",
    "\n",
    "Once it works it will be moved to a script."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d5276a",
   "metadata": {},
   "source": [
    "## Server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479db853",
   "metadata": {},
   "source": [
    "Before running the notebook launch a server. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c1d6f8",
   "metadata": {},
   "source": [
    "```bash\n",
    "export CUDA_VISIBLE_DEVICES=0; trl vllm-serve --max_model_len 12000 --model /home/gbarbadillo/models/Llama-3.1-ARC-Potpourri-Induction-8B\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a751caa",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d209f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\" # 0 is used by the vllm server\n",
    "\n",
    "from unsloth import FastLanguageModel\n",
    "from dataclasses import dataclass\n",
    "from datasets import Dataset\n",
    "\n",
    "from trl import GRPOConfig, GRPOTrainer\n",
    "\n",
    "from arc25.encoders import create_grid_encoder\n",
    "from arc25.utils import load_arc_dataset_with_solutions\n",
    "from arc25.data_augmentation import apply_data_augmentation, get_random_data_augmentation_params\n",
    "from arc25.prompting import create_prompt_from_task\n",
    "# from arc25.collator import get_data_collator\n",
    "from arc25.logging import configure_logging, logging\n",
    "from arc25.parallel_code_execution import run_code_from_predictions\n",
    "\n",
    "configure_logging()\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b93785",
   "metadata": {},
   "source": [
    "## First steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464e8273",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class cfg:\n",
    "    # base model\n",
    "    model_path: str = \"/home/gbarbadillo/models/Llama-3.1-ARC-Potpourri-Induction-8B\"\n",
    "    load_in_4bit: bool = False\n",
    "    max_seq_length: int = 12000\n",
    "    grid_encoder: str = 'ColorNameEncoder()'\n",
    "    # LoRA\n",
    "    lora_r: int = 16\n",
    "    use_rslora: bool = True\n",
    "    # dataset\n",
    "    dataset_path: str = \"/mnt/hdd0/Kaggle/arc25/data/arc-prize-2024/arc-agi_training_challenges.json\"\n",
    "    output_dir: str = \"/mnt/hdd0/Kaggle/arc25/trainings/2025-09-12-debug-grpo-b/debug-reward\"\n",
    "    # training hyperparameters\n",
    "    max_epochs: int = 3\n",
    "    num_generations: int = 8\n",
    "    training_batch_size: int = 1\n",
    "    learning_rate: float = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4665e0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_arc_dataset_with_solutions(cfg.dataset_path)\n",
    "print(f\"Loaded {len(dataset)} tasks from {cfg.dataset_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15c51c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    cfg.model_path, load_in_4bit=cfg.load_in_4bit,fast_inference=False)\n",
    "grid_encoder = create_grid_encoder(cfg.grid_encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4877175a",
   "metadata": {},
   "source": [
    "Let's create a small dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c598ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_id = list(dataset.keys())[0]\n",
    "grpo_dataset = []\n",
    "for _ in range(2):\n",
    "    params = get_random_data_augmentation_params()\n",
    "    task = apply_data_augmentation(dataset[task_id], **params)\n",
    "    prompt = create_prompt_from_task(\n",
    "            task, grid_encoder=grid_encoder, tokenizer=tokenizer, shuffle_train_samples=True)\n",
    "    grpo_dataset.append(dict(prompt=prompt, tasks=task))\n",
    "grpo_dataset = Dataset.from_list(grpo_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf316c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_num_unique_letters(completions, **kwargs):\n",
    "    \"\"\"\n",
    "    Reward function that rewards completions with more unique letters.\n",
    "\n",
    "    As input seems to be receiving: completions, prompts, ground_truth and completion_ids\n",
    "    \"\"\"\n",
    "    logger.info(f\"Computing reward for {len(completions)} completions\")\n",
    "    logger.info(f'Completions: {completions}')\n",
    "    logger.info(f'This are the kwargs: {list(kwargs.keys())}')\n",
    "    # completion_contents = [completion[0][\"content\"] for completion in completions]\n",
    "    rewards = [float(len(set(content))) for content in completions]\n",
    "    logger.info(f'Rewards: {rewards}')\n",
    "    return rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82b9ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def arc_reward(completions, tasks, **kwargs):\n",
    "    \"\"\"\n",
    "    Reward function that rewards completions based on how many test cases they pass.\n",
    "\n",
    "    As input seems to be receiving: completions, prompts, ground_truth and completion_ids\n",
    "    \"\"\"\n",
    "    results = run_code_from_predictions(tasks, list(range(len(completions))), completions, [None]*len(completions), group_results_by_task=False)\n",
    "    logger.info(f\"Reward results: {results}\")\n",
    "    logger.info(f\"Task ids: {[result['task_id'] for result in results]}\")\n",
    "    rewards = [float(result.get('train_correct_grids', 0)) for result in results]\n",
    "    logger.info(f'Rewards: {rewards}')\n",
    "    return rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082aea15",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    llm,\n",
    "    r = cfg.lora_r, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\n",
    "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "        \"gate_proj\", \"up_proj\", \"down_proj\",\n",
    "    ], # Remove QKVO if out of memory\n",
    "    lora_alpha = 64,\n",
    "    use_gradient_checkpointing = \"unsloth\", # Enable long context finetuning\n",
    "    use_rslora = cfg.use_rslora,\n",
    "    # random_state = 3407,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce59b755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/docs/trl/main/en/grpo_trainer#trl.GRPOConfig\n",
    "training_args = GRPOConfig(\n",
    "    output_dir=cfg.output_dir,\n",
    "    num_train_epochs=cfg.max_epochs,\n",
    "    per_device_train_batch_size=cfg.training_batch_size,\n",
    "    num_generations=cfg.num_generations,\n",
    "    gradient_accumulation_steps=2, #cfg.num_generations // cfg.training_batch_size,\n",
    "    learning_rate=cfg.learning_rate,\n",
    "    # generation\n",
    "    use_vllm=True,\n",
    "    vllm_mode=\"server\",\n",
    "    max_completion_length=1024,\n",
    "    max_prompt_length=None,\n",
    "    temperature=1.0,\n",
    "    top_p=0.95,\n",
    "    # wandb\n",
    "    report_to='wandb',\n",
    "    run_name=os.path.basename(cfg.output_dir),\n",
    "    # project=os.path.basename(os.path.dirname(cfg.output_dir)),\n",
    ")\n",
    "os.environ[\"WANDB_PROJECT\"] = os.path.basename(os.path.dirname(cfg.output_dir))\n",
    "# set also the output dir for wandb\n",
    "os.environ[\"WANDB_DIR\"] = cfg.output_dir\n",
    "\n",
    "print(f\"Training arguments: {training_args}\")\n",
    "# Unsloth: We now expect `per_device_train_batch_size` to be a multiple of `num_generations`. ???\n",
    "# Why ??? I want to use gradient accumulation to simulate larger batch sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00cc82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = GRPOTrainer(\n",
    "    model=model,\n",
    "    reward_funcs=arc_reward, #reward_num_unique_letters,\n",
    "    # data_collator=get_data_collator(tokenizer),\n",
    "    args=training_args,\n",
    "    train_dataset=grpo_dataset,\n",
    "    completion_only_loss=True,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1033069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this to reset the vllm server\n",
    "#! curl  -X POST --location http://0.0.0.0:8000/close_communicator/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a6870e",
   "metadata": {},
   "source": [
    "There seem to be some compatibility problems:\n",
    "\n",
    "```\n",
    "This happens when creating the training conf:\n",
    "Unsloth: We now expect `per_device_train_batch_size` to be a multiple of `num_generations`. ???\n",
    "\n",
    "This happens when training\n",
    "AttributeError: 'UnslothGRPOConfig' object has no attribute 'delta'\n",
    "\n",
    "Library versions:\n",
    "unsloth                   2025.9.1                 pypi_0    pypi\n",
    "unsloth-zoo               2025.9.2                 pypi_0    pypi\n",
    "trl                       0.18.0.dev0              pypi_0    pypi\n",
    "\n",
    "# pip index versions <package-name>\n",
    "unsloth (2025.9.4)\n",
    "Available versions: 2025.9.4, 2025.9.3, 2025.9.2, 2025.9.1,\n",
    "trl (0.23.0)\n",
    "Available versions: 0.23.0, 0.22.2, 0.22.1, 0.22.0, 0.21.0, 0.20.0, 0.19.1, 0.19.0, 0.18.2, 0.18.1, 0.18.0\n",
    "\n",
    "I have installed the latest versions of both libraries on the environment `arc25-unsloth`\n",
    "pip install unsloth==2025.9.4\n",
    "pip install trl==0.23.0\n",
    "pip install trl[vllm]\n",
    "\n",
    "Then it gives this error when launching the server.\n",
    "NameError: name 'ParallelismConfig' is not defined. Did you mean: 'parallelism_config'?\n",
    "Solved with: pip install --upgrade accelerate\n",
    "\n",
    "I also have to remove the collator.\n",
    "```\n",
    "\n",
    "This is working, but only did one training step.\n",
    "\n",
    "```\n",
    "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
    "   \\\\   /|    Num examples = 10 | Num Epochs = 1 | Total steps = 1\n",
    "O^O/ \\_/ \\    Batch size per device = 8 | Gradient accumulation steps = 8\n",
    "\\        /    Data Parallel GPUs = 1 | Total batch size (8 x 8 x 1) = 64\n",
    " \"-____-\"     Trainable parameters = 41,943,040 of 8,072,204,288 (0.52% trained)\n",
    "```\n",
    "\n",
    "If I reduce the gradient accumulation steps to 1, increase the number of epochs to 3 then it does 30 steps.\n",
    "\n",
    "Now the problem is that it seems that only be predicting 256 output tokens.\n",
    "\n",
    "Notice "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c8ab6a",
   "metadata": {},
   "source": [
    "## Debug"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4717522",
   "metadata": {},
   "source": [
    "## TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4a4e7f",
   "metadata": {},
   "source": [
    "- [ ] Implement the reward function\n",
    "- [ ] Check if memory is enough\n",
    "- [ ] Can I optimize the bouncing in compute between the two gpus?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arc25-unsloth",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
