{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54676bac",
   "metadata": {},
   "source": [
    "# Prepare BARC data for training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fa8417",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ae4a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from arc25.plot import plot_task\n",
    "from arc25.utils import write_json, load_json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90926069",
   "metadata": {},
   "source": [
    "## Create dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eeb0ed4",
   "metadata": {},
   "source": [
    "### Load and sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cb79eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '/mnt/hdd0/Kaggle/arc25/data/200k_HEAVY_gpt4o-description-gpt4omini-code_generated_problems/data_100k.jsonl'\n",
    "df = pd.read_json(filepath, lines=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc14a943",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_n_train(max_n=None):\n",
    "    # same distribution as the original datasets\n",
    "    n_and_count = [(2, 355), (3, 1281), (4, 433), (5, 123), (6, 43), (7, 17), (8, 6), (10, 2)]\n",
    "    if max_n is not None:\n",
    "        n_and_count = [(n, count) for n, count in n_and_count if n <= max_n]\n",
    "    weights = [count for n, count in n_and_count]\n",
    "    total = sum(weights)\n",
    "    probabilities = [count / total for count in weights]\n",
    "    n_samples = [n for n, count in n_and_count]\n",
    "    n = random.choices(n_samples, weights=probabilities, k=1)[0]\n",
    "    return n\n",
    "\n",
    "sample_n_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bd51a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_task_from_examples(examples, max_attempts=10):\n",
    "    for _ in range(max_attempts):\n",
    "        n_train = sample_n_train(len(examples)-1)\n",
    "        n_test = 1\n",
    "        if n_train + n_test > len(examples):\n",
    "            continue\n",
    "        samples = random.sample(examples, n_train + n_test)\n",
    "        train_examples = samples[:n_train]\n",
    "        tokens = sum(len(ex[0])*len(ex[0][0]) + len(ex[1])*len(ex[1][0]) for ex in samples)\n",
    "        if tokens > 30*30*5:  # max 5 30x30 examples in training\n",
    "            continue\n",
    "        test_examples = samples[n_train:]\n",
    "        task = {'train': [{'input': ex[0], 'output': ex[1]} for ex in train_examples],\n",
    "                'test': [{'input': ex[0], 'output': ex[1]} for ex in test_examples]}\n",
    "        return task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1298b4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {}\n",
    "for idx, examples in tqdm(enumerate(df.examples.values), total=len(df)):\n",
    "    if len(examples) < 3:\n",
    "        continue\n",
    "    task = create_task_from_examples(examples)\n",
    "    if task is not None:\n",
    "        dataset[f'barc_{idx:06d}'] = task\n",
    "len(dataset), len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b0d9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef6863d",
   "metadata": {},
   "source": [
    "### Save whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453a5939",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_json(dataset, '/mnt/hdd0/Kaggle/arc25/data/200k_HEAVY_gpt4o-description-gpt4omini-code_generated_problems/dataset_100k.json.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddb55af",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_json('/mnt/hdd0/Kaggle/arc25/data/200k_HEAVY_gpt4o-description-gpt4omini-code_generated_problems/dataset_100k.json.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9947c9fb",
   "metadata": {},
   "source": [
    "### Save two parts for inference for multi-turn RL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc02742b",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list(dataset.keys())\n",
    "random.shuffle(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01c074e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_parts = 2\n",
    "tasks_per_part = 10000\n",
    "for part in range(n_parts):\n",
    "    print(f'Creating part {part+1}/{n_parts}...')\n",
    "    part_dataset = {}\n",
    "    for key in keys[part*tasks_per_part:(part+1)*tasks_per_part]:\n",
    "        part_dataset[key] = dataset[key]\n",
    "    write_json(part_dataset, f'/mnt/hdd0/Kaggle/arc25/data/200k_HEAVY_gpt4o-description-gpt4omini-code_generated_problems/dataset_10k_part{part+1}.json.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336de5c6",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arc25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
