{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cc6b284",
   "metadata": {},
   "source": [
    "## Collect inference results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b10b936",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59911ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "from arc25.utils import load_json\n",
    "from arc25.metrics import aggregate_metrics, error_analysis\n",
    "\n",
    "plt.plot()\n",
    "plt.close('all')\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 3)\n",
    "mpl.rcParams['lines.linewidth'] = 3\n",
    "mpl.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f18bf07",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33240278",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_predictions(filepaths, max_files=None):\n",
    "    data = None\n",
    "    if max_files is not None:\n",
    "        filepaths = filepaths[:max_files]\n",
    "    for filepath in tqdm(filepaths):\n",
    "        file_data = load_json(filepath)\n",
    "        if data is None:\n",
    "            data = file_data\n",
    "        else:\n",
    "            for task_id, result in file_data.items():\n",
    "                data[task_id].extend(result)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3760373",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7962c6",
   "metadata": {},
   "source": [
    "### 2025-10-14-rl-barc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc437f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_files = 4\n",
    "dfs = dict()\n",
    "filepaths = glob.glob('/mnt/hdd0/Kaggle/arc25/predictions/2025-10-14-rl-barc/baseline/evaluation/*.json.gz')\n",
    "alias = 'baseline'\n",
    "predictions = load_predictions(filepaths, max_files=max_files)\n",
    "dfs[alias] = aggregate_metrics(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39150f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = {\n",
    "    # '8lora-16gen': '/mnt/hdd0/Kaggle/arc25/predictions/2025-10-14-rl-barc/1lora_lr4e-6_arc-v2-no-pixel-score_epochs1_16gen_2accum-steps_repetition-penalty-1.02_masked-truncate_unquantized_beta0.01',\n",
    "    '1lora-16gen': '/mnt/hdd0/Kaggle/arc25/predictions/2025-10-14-rl-barc/8lora_lr2e-6_arc-v2-no-pixel-score_epochs1_16gen_2accum-steps_repetition-penalty-1.02_masked-truncate_unquantized_beta0.01',\n",
    "    '1lora-32gen': '/mnt/hdd0/Kaggle/arc25/predictions/2025-10-14-rl-barc/1lora_lr4e-6_0.05max-grad-norm_arc-v2-no-pixel-score_32gen_4accum-steps_repetition-penalty-1.02_masked-truncate_unquantized_beta0.02',\n",
    "    '1lora-64gen': '/mnt/hdd0/Kaggle/arc25/predictions/2025-10-14-rl-barc/1lora_lr4e-6_0.02max-grad-norm_arc-v2-no-pixel-score_64gen_8accum-steps_repetition-penalty-1.01_masked-truncate_unquantized_beta0.04',\n",
    "    '1lora-128gen': '/mnt/hdd0/Kaggle/arc25/predictions/2025-10-14-rl-barc/1lora_lr4e-6_0.02max-grad-norm_arc-v2-no-pixel-score_128gen_16accum-steps_repetition-penalty-1.01_masked-truncate_unquantized_beta0.04',\n",
    "}\n",
    "\n",
    "for alias, folder in folders.items():\n",
    "    subfolders = sorted(glob.glob(os.path.join(folder, '*')), key=lambda x: int(os.path.basename(x).split('-')[-1]))\n",
    "    for subfolder in subfolders:\n",
    "        print(f\"Processing folder: {subfolder}\")\n",
    "        filepaths = glob.glob(os.path.join(subfolder, 'evaluation/*.json.gz'))\n",
    "        if not filepaths:\n",
    "            continue\n",
    "        predictions = load_predictions(filepaths, max_files=max_files)\n",
    "        dfs[alias + '_' + os.path.basename(subfolder).split('_')[0]] = aggregate_metrics(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6766cd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = None\n",
    "for alias, df in dfs.items():\n",
    "    if results_df is None:\n",
    "        results_df = pd.DataFrame(columns=df.columns)\n",
    "    results_df.loc[alias] = df.loc['MEAN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e82076",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_results = dict()\n",
    "for key in folders.keys():\n",
    "    experiment_results[key] = results_df.loc[['baseline'] + [k for k in results_df.index if k.startswith(key)]]\n",
    "    experiment_results[key]['training_steps'] = list(map(lambda x: int(x.split('-')[-1]) if x != 'baseline' else 0, experiment_results[key].index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55850b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_results['1lora-16gen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01747464",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_groups = [\n",
    "    [column for column in results_df.columns if column.startswith('train_')],\n",
    "    [column for column in results_df.columns if column.startswith('test_')],\n",
    "    ['valid code', 'valid outputs', 'unique outputs', 'is_correct']\n",
    "]\n",
    "\n",
    "for metrics in metric_groups:\n",
    "    for plot_idx, column in enumerate(metrics, 1):\n",
    "        plt.subplot(1, len(metrics), plot_idx)\n",
    "        for key in folders.keys():\n",
    "            plt.plot(\n",
    "                experiment_results[key]['training_steps'],\n",
    "                experiment_results[key][column],\n",
    "                marker='o',\n",
    "                label=key\n",
    "            )\n",
    "        plt.title(column)\n",
    "        plt.xlabel('Training Steps')\n",
    "        plt.ylabel(column)\n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391e06a5",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arc25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
